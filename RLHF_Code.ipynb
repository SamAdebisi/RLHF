{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import spaces \n",
    "import numpy as np \n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader, Subset \n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification \n",
    "from datasets import load_dataset \n",
    "import random \n",
    "from stable_baselines3 import PPO \n",
    "from stable_baselines3.common.vec_env import DummyVecEnv \n",
    "from stable_baselines3.common.evaluation import evaluate_policy \n",
    "\n",
    "# Set random seed for reproducibility \n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load SST-2 dataset \n",
    "dataset = load_dataset(\"sst2\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "class SST2Dataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.data = dataset[split]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx][\"sentence\"]\n",
    "        label = self.data[idx][\"label\"]\n",
    "        encoding = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(label)\n",
    "        }\n",
    "\n",
    "# Create full datasets and sample subsets\n",
    "full_train_dataset = SST2Dataset(\"train\")\n",
    "full_eval_dataset  = SST2Dataset(\"validation\")\n",
    "\n",
    "train_indices = random.sample(range(len(full_train_dataset)), 96)\n",
    "eval_indices  = random.sample(range(len(full_eval_dataset)), 32)\n",
    "\n",
    "train_dataset = Subset(full_train_dataset, train_indices)\n",
    "eval_dataset  = Subset(full_eval_dataset, eval_indices)\n",
    "\n",
    "class SST2Environment(gym.Env):\n",
    "    def __init__(self, dataset):\n",
    "        super(SST2Environment, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.current_index = 0\n",
    "        \n",
    "        self.action_space = spaces.Discrete(2)  # Binary classification\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(768,), dtype=np.float32)  # DistilBERT hidden size\n",
    "        \n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_index = 0\n",
    "        return self._get_observation()\n",
    "    \n",
    "    def step(self, action):\n",
    "        reward = 1.0 if action == self.dataset[self.current_index][\"labels\"].item() else -1.0\n",
    "        done = (self.current_index == len(self.dataset) - 1)\n",
    "        self.current_index = (self.current_index + 1) % len(self.dataset)\n",
    "        return self._get_observation(), reward, done, {}\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        input_ids = self.dataset[self.current_index][\"input_ids\"].unsqueeze(0)\n",
    "        attention_mask = self.dataset[self.current_index][\"attention_mask\"].unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = SST2Environment(train_dataset)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Create the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=1000)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_env = SST2Environment(eval_dataset)\n",
    "eval_env = DummyVecEnv([lambda: eval_env])\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10)\n",
    "\n",
    "print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "# Optional: Save the model\n",
    "model.save(\"ppo_sst2\")\n",
    "\n",
    "print(\"Training and evaluation completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
